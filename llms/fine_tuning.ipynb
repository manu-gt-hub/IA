{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c790a1a1-b783-4ca2-b420-6797e545b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from openai import OpenAI\n",
    "import httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afffe6b-4d07-41ea-852b-d5773aa62ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCLUSIONS:\n",
    "#\n",
    "# - the more epochs, the better for training accuracy BUT there is a limit, if I put more than certain number it fails, I saw recommended is from 3-5 epochs\n",
    "# - the more data, the better. openAI recommends 50-100 examples aprox. I initially tried with 6-8 rows and the result was really bad, then I tried with a 170 rows dataset and it worked better, at least answering cities and degrees\n",
    "#   but it still needs to improve accuracy with the degrees because they don't match the 100% of the times\n",
    "# - the answers improved A LOT changing the content of the training data from: { role-system, role-assistant } to: { role-system, role-user (question), role-assistant }\n",
    "# - there is validation file parameter, it could be interesting to know how is the correct format to use it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c3c5afc-22ce-4cba-8ef7-fdb8041385e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "openai = OpenAI(http_client=httpx.Client(verify=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60765e51-f946-455f-aba7-4f8429786c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts = [\n",
    "    \"what is the temperature in Tegucigalpa today?\",\n",
    "    \"what is the temperature in Yamoussoukro today?\",\n",
    "    \"what is the temperature in Rabat today?\",\n",
    "    \"what is the temperature in Wellington today?\",\n",
    "    \"what is the temperature in New York today?\"\n",
    "]\n",
    "\n",
    "def ask_for_test_prompts(show_model=False):\n",
    "\n",
    "    if show_model:\n",
    "        print(f\"using {model_name} model\\n\")\n",
    "        \n",
    "    for q in test_prompts:\n",
    "        print(f\"question: {q}\\n\")\n",
    "        a = gpt_fine_tuned(q,show_model)\n",
    "        print(f\"  -answer: {a}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5924a2fb-1563-49bd-b776-0c5ef3689f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_fine_tuned(user_prompt, show_model=False):\n",
    "\n",
    "    system_message = \"you are an assistant, just provide quick answers\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model_name, \n",
    "        messages=messages,\n",
    "        seed=42,\n",
    "        max_tokens=50,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    return reply\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7aa5081f-3190-4c5a-87c4-9076952f453b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using gpt-4o-mini model\n",
      "\n",
      "question: what is the temperature in Tegucigalpa today?\n",
      "\n",
      "  -answer: I don't have real-time data access to provide current temperatures. Please check a weather website or app for the latest information.\n",
      "\n",
      "question: what is the temperature in Yamoussoukro today?\n",
      "\n",
      "  -answer: I don't have real-time data access to provide current temperatures. Please check a weather website or app for the latest information.\n",
      "\n",
      "question: what is the temperature in Rabat today?\n",
      "\n",
      "  -answer: I don't have real-time data access to provide current temperatures. Please check a weather website or app for the latest information.\n",
      "\n",
      "question: what is the temperature in Wellington today?\n",
      "\n",
      "  -answer: I don't have real-time data access to provide current temperatures. Please check a weather website or app for the latest information.\n",
      "\n",
      "question: what is the temperature in New York today?\n",
      "\n",
      "  -answer: I don't have real-time data access to provide current temperatures. Please check a weather website or app for the latest information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST BEFORE FINE TUNING\n",
    "\n",
    "ask_for_test_prompts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60e79baa-a207-449f-a138-7628001cdfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fine tuning data \n",
    "\n",
    "with open(\"./resources/fine_tuning_info.jsonl\", \"rb\") as f:\n",
    "    train_file = openai.files.create(file=f, purpose=\"fine-tune\")\n",
    "\n",
    "with open(\"./resources/fine_tuning_validation.jsonl\", \"rb\") as f:\n",
    "    validation_file = openai.files.create(file=f, purpose=\"fine-tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed0d97db-ffe4-4a39-a588-5ba701dc498c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-1rodriZljdy3TddfP2tCD1gF', created_at=1747401764, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs=10), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-l5pA9yLCUC9WzyRoifiw8iGF', result_files=[], seed=42, status='validating_files', trained_tokens=None, training_file='file-C1iyTXfVQ6mrKdnidqriq3', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs=10)), type='supervised'), user_provided_suffix='fine-tuned', metadata=None, usage_metrics=None, shared_with_openai=False, eval_id=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run fine tuning\n",
    "\n",
    "openai.fine_tuning.jobs.create(\n",
    "    training_file=train_file.id,    \n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    seed=42,\n",
    "    hyperparameters={\"n_epochs\": 10},\n",
    "    suffix=\"fine-tuned\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f74c3b-2653-4acd-917d-a0a5523a2696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-1rodriZljdy3TddfP2tCD1gF', created_at=1747401764, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs=10), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-l5pA9yLCUC9WzyRoifiw8iGF', result_files=[], seed=42, status='validating_files', trained_tokens=None, training_file='file-C1iyTXfVQ6mrKdnidqriq3', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs=10)), type='supervised'), user_provided_suffix='fine-tuned', metadata=None, usage_metrics=None, shared_with_openai=False, eval_id=None)], has_more=True, object='list')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.fine_tuning.jobs.list(limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7abe3fd-31ce-4972-81e9-fdd2b590da60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftjob-1rodriZljdy3TddfP2tCD1gF\n"
     ]
    }
   ],
   "source": [
    "job_id = openai.fine_tuning.jobs.list(limit=1).data[0].id\n",
    "\n",
    "print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "322786bf-2ae8-4b33-8a8a-b6e8724a885c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-1rodriZljdy3TddfP2tCD1gF', created_at=1747401764, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs=10), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-l5pA9yLCUC9WzyRoifiw8iGF', result_files=[], seed=42, status='validating_files', trained_tokens=None, training_file='file-C1iyTXfVQ6mrKdnidqriq3', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs=10)), type='supervised'), user_provided_suffix='fine-tuned', metadata=None, usage_metrics=None, shared_with_openai=False, eval_id=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.fine_tuning.jobs.retrieve(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb611e5e-061f-451e-a6d2-56bb30c87dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID: ftevent-QJQaFrBoTgeSU8uhv97UURMF\n",
      "Created At: 1747403589\n",
      "Level: info\n",
      "Message: The job has successfully completed\n",
      "Data: {}\n",
      "------\n",
      "Event ID: ftevent-812iJTX7LrIeX2QdmD0k1lwz\n",
      "Created At: 1747403583\n",
      "Level: info\n",
      "Message: New fine-tuned model created\n",
      "Data: {}\n",
      "------\n",
      "Event ID: ftevent-671RVL7d8aN9S0UXhA1QyDCV\n",
      "Created At: 1747403583\n",
      "Level: info\n",
      "Message: Checkpoint created at step 1530\n",
      "Data: {}\n",
      "------\n",
      "Event ID: ftevent-JP0QaChSa597iJr21uB3yZjr\n",
      "Created At: 1747403583\n",
      "Level: info\n",
      "Message: Checkpoint created at step 1360\n",
      "Data: {}\n",
      "------\n",
      "Event ID: ftevent-3HN2zO3aKjrxNAR5VJL8jfNp\n",
      "Created At: 1747403556\n",
      "Level: info\n",
      "Message: Step 1700/1700: training loss=0.00\n",
      "Data: {'step': 1700, 'train_loss': 4.695012103184126e-05, 'total_steps': 1700, 'train_mean_token_accuracy': 1.0}\n",
      "------\n",
      "Event ID: ftevent-z7VNdocgyYMGv3Mpxvk6DgOR\n",
      "Created At: 1747403556\n",
      "Level: info\n",
      "Message: Step 1699/1700: training loss=0.00\n",
      "Data: {'step': 1699, 'train_loss': 4.38690185546875e-05, 'total_steps': 1700, 'train_mean_token_accuracy': 1.0}\n",
      "------\n",
      "Event ID: ftevent-5uRyp5hkA95rp7W0C5QyZFAE\n",
      "Created At: 1747403553\n",
      "Level: info\n",
      "Message: Step 1698/1700: training loss=0.00\n",
      "Data: {'step': 1698, 'train_loss': 2.983638296427671e-05, 'total_steps': 1700, 'train_mean_token_accuracy': 1.0}\n",
      "------\n",
      "Event ID: ftevent-0Nt9Rq0jbDQC5jtJnax7XV18\n",
      "Created At: 1747403553\n",
      "Level: info\n",
      "Message: Step 1697/1700: training loss=0.00\n",
      "Data: {'step': 1697, 'train_loss': 3.447899507591501e-05, 'total_steps': 1700, 'train_mean_token_accuracy': 1.0}\n",
      "------\n",
      "Event ID: ftevent-bsLv1DUhRjK8A98caaana0cM\n",
      "Created At: 1747403553\n",
      "Level: info\n",
      "Message: Step 1696/1700: training loss=0.00\n",
      "Data: {'step': 1696, 'train_loss': 3.374540028744377e-05, 'total_steps': 1700, 'train_mean_token_accuracy': 1.0}\n",
      "------\n",
      "Event ID: ftevent-335Dx9S8xon2Ud2A9B0dJhDO\n",
      "Created At: 1747403550\n",
      "Level: info\n",
      "Message: Step 1695/1700: training loss=0.00\n",
      "Data: {'step': 1695, 'train_loss': 3.3892116334754974e-05, 'total_steps': 1700, 'train_mean_token_accuracy': 1.0}\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "break_loop = False\n",
    "\n",
    "while True:\n",
    "    \n",
    "    clear_output(wait=True)  # clear output on each iteration\n",
    "\n",
    "    events = openai.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=10).data\n",
    "\n",
    "    for event in events:\n",
    "        print(f\"Event ID: {event.id}\")\n",
    "        print(f\"Created At: {event.created_at}\")\n",
    "        print(f\"Level: {event.level}\")\n",
    "        print(f\"Message: {event.message}\")\n",
    "        print(f\"Data: {event.data}\")\n",
    "        print(\"------\")\n",
    "        \n",
    "        # flags to exit the loop\n",
    "        if \"The job has successfully completed\" in event.message or event.level == \"error\":\n",
    "            break_loop = True\n",
    "\n",
    "    if break_loop:\n",
    "        break\n",
    "    \n",
    "    time.sleep(20)  # wait 20 seconds on each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b1d601c-07d7-4374-bc2a-2053b4502e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft:gpt-4o-mini-2024-07-18:personal:fine-tuned:BXpmhXeF\n"
     ]
    }
   ],
   "source": [
    "model_name = openai.fine_tuning.jobs.retrieve(job_id).fine_tuned_model\n",
    "print(fine_tuned_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fca45abf-7ab3-4847-aecb-e648249c5ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ft:gpt-4o-mini-2024-07-18:personal:fine-tuned:BXpmhXeF model\n",
      "\n",
      "question: what is the temperature in Tegucigalpa today?\n",
      "\n",
      "  -answer: It's a cool 22°C in Tegucigalpa today.\n",
      "\n",
      "question: what is the temperature in Yamoussoukro today?\n",
      "\n",
      "  -answer: It's a warm 30°C in Yamoussoukro today.\n",
      "\n",
      "question: what is the temperature in Rabat today?\n",
      "\n",
      "  -answer: It's a cool 18°C in Rabat today.\n",
      "\n",
      "question: what is the temperature in Wellington today?\n",
      "\n",
      "  -answer: It's a cool 12°C in Wellington today.\n",
      "\n",
      "question: what is the temperature in New York today?\n",
      "\n",
      "  -answer: It's a cool 58°F in New York today.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST AFTER FINE TUNING\n",
    "\n",
    "ask_for_test_prompts(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
