{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0afffe6b-4d07-41ea-852b-d5773aa62ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCLUSIONS:\n",
    "#\n",
    "# - the more epochs, the better for training accuracy BUT there is a limit, if I put more than certain number it fails, I saw recommended is from 3-5 epochs\n",
    "# - the mor data, the better. I initially tried with 6-8 rows and the result was really bad, then I tried with a 170 rows dataset and it worked better, at least answering cities and degrees\n",
    "#   but it still needs to improve accuracy with the degrees because they don't match the 100% of the times\n",
    "# - the answers improved A LOT changing the content of the training data from: { role-system, role-assistant } to: { role-system, role-user (question), role-assistant }\n",
    "# - there is validation file parameter, it could be interesting to know how is the correct format to use it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c790a1a1-b783-4ca2-b420-6797e545b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, math, json, random, time, pickle\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import httpx\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c3c5afc-22ce-4cba-8ef7-fdb8041385e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "openai = OpenAI(http_client=httpx.Client(verify=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60765e51-f946-455f-aba7-4f8429786c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts = [\n",
    "    \"what is the temperature in Tegucigalpa today?\",\n",
    "    \"what is the temperature in Yamoussoukro today?\",\n",
    "    \"what is the temperature in Rabat today?\",\n",
    "    \"what is the temperature in Wellington today?\",\n",
    "    \"what is the temperature in New York today?\"\n",
    "]\n",
    "\n",
    "def ask_for_test_prompts(show_model=False):\n",
    "\n",
    "    if show_model:\n",
    "        print(f\"using {model_name} model\\n\")\n",
    "        \n",
    "    for q in test_prompts:\n",
    "        print(f\"question: {q}\\n\")\n",
    "        a = gpt_fine_tuned(q,show_model)\n",
    "        print(f\"  -answer: {a}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5924a2fb-1563-49bd-b776-0c5ef3689f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_fine_tuned(user_prompt, show_model=False):\n",
    "\n",
    "    system_message = \"you are an assistant, just provide quick answers\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model_name, \n",
    "        messages=messages,\n",
    "        seed=42,\n",
    "        max_tokens=50,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "    return reply\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aa5081f-3190-4c5a-87c4-9076952f453b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using gpt-4o-mini model\n",
      "\n",
      "question: what is the temperature in Tegucigalpa today?\n",
      "\n",
      "  -answer: I don't have real-time data access to provide current temperatures. Please check a weather website or app for the latest information.\n",
      "\n",
      "question: what is the temperature in Yamoussoukro today?\n",
      "\n",
      "  -answer: I don't have real-time data access to provide current temperatures. Please check a weather website or app for the latest information.\n",
      "\n",
      "question: what is the temperature in Rabat today?\n",
      "\n",
      "  -answer: I don't have real-time data access to provide current temperatures. Please check a weather website or app for the latest information.\n",
      "\n",
      "question: what is the temperature in Wellington today?\n",
      "\n",
      "  -answer: I don't have real-time data access to provide current temperatures. Please check a weather website or app for the latest information.\n",
      "\n",
      "question: what is the temperature in New York today?\n",
      "\n",
      "  -answer: I don't have real-time data access. Please check a weather website or app for the current temperature in New York.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST BEFORE FINE TUNING\n",
    "\n",
    "ask_for_test_prompts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60e79baa-a207-449f-a138-7628001cdfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fine tuning data \n",
    "\n",
    "with open(\"./resources/fine_tuning_info.jsonl\", \"rb\") as f:\n",
    "    train_file = openai.files.create(file=f, purpose=\"fine-tune\")\n",
    "\n",
    "with open(\"./resources/fine_tuning_validation.jsonl\", \"rb\") as f:\n",
    "    validation_file = openai.files.create(file=f, purpose=\"fine-tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed0d97db-ffe4-4a39-a588-5ba701dc498c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-ySj7R3UxJuFtEO8QZpqI2CvE', created_at=1748598578, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs=1), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-l5pA9yLCUC9WzyRoifiw8iGF', result_files=[], seed=42, status='validating_files', trained_tokens=None, training_file='file-7Kn48bW5cBi7fiiCA2zivm', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs=1)), type='supervised'), user_provided_suffix='fine-tuned', metadata=None, usage_metrics=None, shared_with_openai=False, eval_id=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run fine tuning\n",
    "\n",
    "openai.fine_tuning.jobs.create(\n",
    "    training_file=train_file.id,    \n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    seed=42,\n",
    "    hyperparameters={\"n_epochs\": 1},\n",
    "    suffix=\"fine-tuned\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6f74c3b-2653-4acd-917d-a0a5523a2696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-ySj7R3UxJuFtEO8QZpqI2CvE', created_at=1748598578, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs=1), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-l5pA9yLCUC9WzyRoifiw8iGF', result_files=[], seed=42, status='validating_files', trained_tokens=None, training_file='file-7Kn48bW5cBi7fiiCA2zivm', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs=1)), type='supervised'), user_provided_suffix='fine-tuned', metadata=None, usage_metrics=None, shared_with_openai=False, eval_id=None)], has_more=True, object='list')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.fine_tuning.jobs.list(limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7abe3fd-31ce-4972-81e9-fdd2b590da60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftjob-ySj7R3UxJuFtEO8QZpqI2CvE\n"
     ]
    }
   ],
   "source": [
    "job_id = openai.fine_tuning.jobs.list(limit=1).data[0].id\n",
    "\n",
    "print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "322786bf-2ae8-4b33-8a8a-b6e8724a885c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-ySj7R3UxJuFtEO8QZpqI2CvE', created_at=1748598578, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs=1), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-l5pA9yLCUC9WzyRoifiw8iGF', result_files=[], seed=42, status='validating_files', trained_tokens=None, training_file='file-7Kn48bW5cBi7fiiCA2zivm', validation_file=None, estimated_finish=None, integrations=[], method=Method(dpo=None, supervised=MethodSupervised(hyperparameters=MethodSupervisedHyperparameters(batch_size='auto', learning_rate_multiplier='auto', n_epochs=1)), type='supervised'), user_provided_suffix='fine-tuned', metadata=None, usage_metrics=None, shared_with_openai=False, eval_id=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.fine_tuning.jobs.retrieve(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb611e5e-061f-451e-a6d2-56bb30c87dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID: ftevent-b60ttYSadWzxSxeRORAoaqBT\n",
      "Created At: 1748599863\n",
      "Level: info\n",
      "Message: The job has successfully completed\n",
      "Data: {}\n",
      "------\n",
      "Event ID: ftevent-v5WFd3i20ybnCKgzvn1e2xhx\n",
      "Created At: 1748599859\n",
      "Level: info\n",
      "Message: Usage policy evaluations completed, model is now enabled for sampling\n",
      "Data: {}\n",
      "------\n",
      "Event ID: ftevent-RXVcVeQAenJwrCrnMmL1nnkU\n",
      "Created At: 1748599068\n",
      "Level: info\n",
      "Message: Evaluating model against our usage policies before enabling\n",
      "Data: {}\n",
      "------\n",
      "Event ID: ftevent-RVJjwCw4lugEJ3Xw07uOUg6t\n",
      "Created At: 1748599068\n",
      "Level: info\n",
      "Message: New fine-tuned model created\n",
      "Data: {}\n",
      "------\n",
      "Event ID: ftevent-36H82vxcrz3y6sMRKO5QmKkV\n",
      "Created At: 1748599037\n",
      "Level: info\n",
      "Message: Step 170/170: training loss=0.01\n",
      "Data: {'step': 170, 'train_loss': 0.011498996056616306, 'total_steps': 170, 'train_mean_token_accuracy': 1.0}\n",
      "------\n",
      "Event ID: ftevent-yjkdLjz6oP6I3zU6F8pP6YsH\n",
      "Created At: 1748599037\n",
      "Level: info\n",
      "Message: Step 169/170: training loss=0.00\n",
      "Data: {'step': 169, 'train_loss': 4.468645420274697e-05, 'total_steps': 170, 'train_mean_token_accuracy': 1.0}\n",
      "------\n",
      "Event ID: ftevent-FHqXbpudoMvXi0f3krUG3FSO\n",
      "Created At: 1748599037\n",
      "Level: info\n",
      "Message: Step 168/170: training loss=0.00\n",
      "Data: {'step': 168, 'train_loss': 4.4309177610557526e-05, 'total_steps': 170, 'train_mean_token_accuracy': 1.0}\n",
      "------\n",
      "Event ID: ftevent-STEwzCIgF8xTIPsFgCDB2uft\n",
      "Created At: 1748599037\n",
      "Level: info\n",
      "Message: Step 167/170: training loss=0.00\n",
      "Data: {'step': 167, 'train_loss': 3.403883602004498e-05, 'total_steps': 170, 'train_mean_token_accuracy': 1.0}\n",
      "------\n",
      "Event ID: ftevent-cLO1GTzw4JGPPcw8MvS116OV\n",
      "Created At: 1748599037\n",
      "Level: info\n",
      "Message: Step 166/170: training loss=0.00\n",
      "Data: {'step': 166, 'train_loss': 8.39233416627394e-06, 'total_steps': 170, 'train_mean_token_accuracy': 1.0}\n",
      "------\n",
      "Event ID: ftevent-qTzOkaMghA2Q4qAh1GajZjcc\n",
      "Created At: 1748599037\n",
      "Level: info\n",
      "Message: Step 165/170: training loss=0.00\n",
      "Data: {'step': 165, 'train_loss': 3.946744618588127e-05, 'total_steps': 170, 'train_mean_token_accuracy': 1.0}\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "finished_job = False\n",
    "\n",
    "while finished_job == False:\n",
    "    \n",
    "    clear_output(wait=True)  # clear output on each iteration\n",
    "\n",
    "    events = openai.fine_tuning.jobs.list_events(fine_tuning_job_id=job_id, limit=10).data\n",
    "\n",
    "    for event in events:\n",
    "        print(f\"Event ID: {event.id}\")\n",
    "        print(f\"Created At: {event.created_at}\")\n",
    "        print(f\"Level: {event.level}\")\n",
    "        print(f\"Message: {event.message}\")\n",
    "        print(f\"Data: {event.data}\")\n",
    "        print(\"------\")\n",
    "        \n",
    "        # flags to exit the loop\n",
    "        if \"The job has successfully completed\" in event.message or event.level == \"error\":\n",
    "            finished_job = True\n",
    "    \n",
    "    time.sleep(20)  # wait 20 seconds on each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d601c-07d7-4374-bc2a-2053b4502e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = openai.fine_tuning.jobs.retrieve(job_id).fine_tuned_model\n",
    "print(fine_tuned_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca45abf-7ab3-4847-aecb-e648249c5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST AFTER FINE TUNING\n",
    "\n",
    "ask_for_test_prompts(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
