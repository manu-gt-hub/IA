{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create meeting minutes from an Audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import requests\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "AUDIO_MODEL = \"whisper-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp3 path\n",
    "audio_filename = \"./resources/audio_sample.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable SSL warnings (optional but not recommended in production)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OpenAI key from environment\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "openai = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe audio\n",
    "api_url = \"https://api.openai.com/v1/audio/transcriptions\"\n",
    "with open(audio_filename, \"rb\") as audio_file:\n",
    "    files = {\"file\": audio_file}\n",
    "    data = {\"model\": AUDIO_MODEL, \"response_format\": \"text\"}\n",
    "    headers = {\"Authorization\": f\"Bearer {openai_api_key}\"}\n",
    "    response = requests.post(api_url, files=files, data=data, headers=headers, verify=False)\n",
    "transcription = response.text\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate meeting minutes from transcription\n",
    "system_message = \"You are an assistant that produces minutes of meetings from transcripts, with summary, key discussion points, in markdown.\"\n",
    "user_prompt = f\"Below is an extract transcript from a conversation. Please write minutes in markdown, including a summary with any relevant discussion points;\\n{transcription}\"\n",
    "response = ollama.chat(\n",
    "    model=\"llama3.2\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    ")\n",
    "llm_response = response[\"message\"][\"content\"]\n",
    "display(Markdown(llm_response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
