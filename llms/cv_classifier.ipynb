{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "552f7439-9171-4eb7-9168-1278b61f38bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCLUSIONS\n",
    "#\n",
    "# the key point is to retrieve the senioprity from the CV (overall and specific)\n",
    "# we could use another tool to extract it and send it to the LLM already gathered to improve its performance\n",
    "# alternative: use the LLM to get every experience the candidate has and calculate and store the experience using code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78532789-97ed-48db-91ce-2cd4ad13b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import ollama\n",
    "from IPython.display import Markdown, display\n",
    "import pdfplumber\n",
    "from docx import Document\n",
    "import pprint\n",
    "import os\n",
    "\n",
    "seniority = \"senior\"\n",
    "\n",
    "job_desc_text = f\"\"\"\n",
    "Position Description:\n",
    "\n",
    "We are seeking a {seniority} Data Engineer to design, build, and maintain scalable data pipelines. The ideal candidate will have expertise in SQL, ETL processes, and cloud technologies, collaborating closely with Data Scientists to ensure data integration and quality.\n",
    "\n",
    "Responsibilities:\n",
    "\n",
    "Manage cloud data storage systems.\n",
    "Collaborate with data scientists to meet data requirements.\n",
    "Ensure data quality and security.\n",
    "Automate data processes.\n",
    "Monitor and troubleshoot data systems.\n",
    "Optimize Big Data solutions.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "Education: Degree in Computer Science or related field.\n",
    "Proficiency in programming languages such as Python, Go, or Rust.\n",
    "Strong SQL skills.\n",
    "Experience with Hadoop and Kafka.\n",
    "Familiarity with cloud platforms (IBM Cloud, Oracle Cloud).\n",
    "Knowledge of data orchestration tools like Prefect or Luigi.\n",
    "Experience in CI/CD tools (GitLab CI, CircleCI).\n",
    "\n",
    "Desirable:\n",
    "\n",
    "Experience with Snowflake.\n",
    "Knowledge of visualization tools (Tableau, PowerBI).\n",
    "Familiarity with Docker or Kubernetes.\n",
    "Understanding of agile methodologies.\n",
    "Cloud or big data certifications.\n",
    "Multicultural experience.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f23468-20ea-407e-ac85-cc8e2cf6f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Función para leer el contenido de un archivo .docx\n",
    "def read_docx(cv_path):\n",
    "    try:\n",
    "        # Cargar el documento\n",
    "        doc = Document(cv_path)\n",
    "        \n",
    "        # Leer el contenido del documento\n",
    "        contenido = []\n",
    "        for parrafo in doc.paragraphs:\n",
    "            contenido.append(parrafo.text)\n",
    "        \n",
    "        return '\\n'.join(contenido)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def read_doc(cv_path):\n",
    "    try:\n",
    "        # Inicializar la aplicación de Word\n",
    "        word = win32com.client.Dispatch(\"Word.Application\")\n",
    "        word.Visible = False\n",
    "        \n",
    "        # Abrir el documento\n",
    "        doc = word.Documents.Open(cv_path)\n",
    "        \n",
    "        # Leer el contenido del documento\n",
    "        contenido = doc.Content.Text\n",
    "        \n",
    "        # Cerrar el documento y la aplicación de Word\n",
    "        doc.Close(False)\n",
    "        word.Quit()\n",
    "        \n",
    "        return contenido\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def read_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text()\n",
    "        return text\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_text_from_cv(cv_path):\n",
    "    cv_text = read_pdf(cv_path)\n",
    "    if cv_text is None:\n",
    "        cv_text = read_docx(cv_path)\n",
    "        if cv_text is None:\n",
    "            cv_text =read_doc(cv_path)\n",
    "\n",
    "    return cv_text\n",
    "\n",
    "\n",
    "def get_job_description(url):\n",
    "    class_name = 'wiki-content'\n",
    "    # Hacer la solicitud HTTP\n",
    "    response = requests.get(url, verify = False)\n",
    "    \n",
    "    # Verificar que la solicitud fue exitosa\n",
    "    if response.status_code == 200:\n",
    "        # Analizar el contenido HTML\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Encontrar todos los elementos con la clase especificada\n",
    "        elements = soup.find_all(class_=class_name)\n",
    "        \n",
    "        # Extraer el texto de esos elementos\n",
    "        text = '\\n'.join([element.get_text(separator='\\n').strip() for element in elements])\n",
    "        return text\n",
    "    else:\n",
    "        return f\"Error: Unable to fetch the page. Status code: {response.status_code}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3430549e-7dd9-4de9-8d28-ea5163613c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    }
   ],
   "source": [
    "roles = [\"data engineer\",\"full stack developer\",\"machine learning engineer\",\"data scientist\"]\n",
    "seniority_dict = {\n",
    "    \"senior\" : \"more than 4 years of experience in total\",\n",
    "    \"mid-senior\" : \"between 2 and 4 years of experience in total\",\n",
    "    \"junior\" : \"between 0 and 2 years of experience in total\"\n",
    "}\n",
    "\n",
    "directorio = './resources/cvs_landing'\n",
    "\n",
    "descriptions_dict = {}\n",
    "\n",
    "for nombre_archivo in os.listdir(directorio):\n",
    "    ruta_archivo = os.path.join(directorio, nombre_archivo)\n",
    "    if os.path.isfile(ruta_archivo):\n",
    "        cv_text = extract_text_from_cv(ruta_archivo)\n",
    "        if cv_text is not None:\n",
    "            \n",
    "            words = cv_text.split()    \n",
    "            num_of_words = len(words)\n",
    "\n",
    "            if num_of_words > 5:    \n",
    "                descriptions_dict[nombre_archivo] = cv_text\n",
    "\n",
    "for filename,desc in descriptions_dict.items():\n",
    "    \n",
    "        descriptions_dict[filename] = desc\n",
    "        #print(filename+\"\\n\\n\"+desc+\"\\n-------------------------------------------------------------------------------\\n\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ee16bc2-85e6-4cb7-8c6c-d53a48ed8b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_prompt():\n",
    "    prompt = \"\"\n",
    "    \n",
    "    prompt += f\"\"\"answer me with a list of candidates based on this dictionary: \\n\\n\"\"\"\n",
    "    \n",
    "    for fn,desc in descriptions_dict.items():\n",
    "        prompt += desc + \"\\n\\n\"\n",
    "    \n",
    "    prompt += f\"\"\"from the first interesting candidate we should interview to the less for the job description: {job_desc_text},\n",
    "            pay attention to the candidate's seniority level and the rquired for the job, also the technologies that the candidates manage. the answer has to be ready to be printed in markdown and a summarized description of all the candidates.\"\"\"\n",
    "    return prompt\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4060d846-3f9d-4dca-af0f-7318ec4f0188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Candidate Evaluation Summary\n",
       "#### Senior Data Engineer Position Requirements\n",
       "\n",
       "| Requirement | Brandon Connor | Elara Quinn | Marlowe | John Smith | Thaddeus |\n",
       "| --- | --- | --- | --- | --- | --- |\n",
       "| Education | B.S. Computer Science | University of Texas - Bachelor of Science, Computer Science | Bachelor of Science in Computer Science | BS, Computer Science, Texas University, Austin | Bachelor of Science in Computer Science |\n",
       "| Programming Language Proficiency | Python, SQL, Spark | MySQL, Apache NiFi, Amazon Redshift, Apache Hadoop, AWS, Tableau | PyTorch, Java, SQL, Hadoop | Python, SQL, Java, Hadoop, MongoDB | Python, SQL, Apache NiFi, AWS |\n",
       "| Experience | Data Engineering Intern (2020-2022) | Data Engineer Intern (2024), Junior Data Engineer (2023-present) | Software Development Intern (2019-2020), Data Engineer (2023-present) | Data Engineer at FNB Nong Phai (2020-2021), ABSA (2015-2017) | Junior Data Engineer (2023-present) |\n",
       "| Seniority Level | Entry-Level to Mid-Level | Mid-Level | Mid-Level to Senior | Senior | Senior |\n",
       "\n",
       "#### Ranking from Most Suitable to Least Suitable\n",
       "\n",
       "Based on the candidate's seniority level and experience with required technologies, the ranking is as follows:\n",
       "\n",
       "1. John Smith\n",
       "2. Marlowe\n",
       "3. Elara Quinn\n",
       "4. Brandon Connor\n",
       "5. Thaddeus"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "response = ollama.chat(\n",
    "model=\"llama3.2\",\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": generate_prompt()\n",
    "    }\n",
    "],\n",
    ")\n",
    "llm_response = response[\"message\"][\"content\"]\n",
    "display(Markdown(llm_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bb2b37-dccd-4630-85b3-889c4cb8f013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
