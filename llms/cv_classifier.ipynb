{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78532789-97ed-48db-91ce-2cd4ad13b8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANGUTI\\AppData\\Local\\anaconda3\\envs\\llms\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'fst-confluence.dot.app.corpintra.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text_from_class(url, class_name):\n",
    "    # Hacer la solicitud HTTP\n",
    "    response = requests.get(url, verify = False)\n",
    "    \n",
    "    # Verificar que la solicitud fue exitosa\n",
    "    if response.status_code == 200:\n",
    "        # Analizar el contenido HTML\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Encontrar todos los elementos con la clase especificada\n",
    "        elements = soup.find_all(class_=class_name)\n",
    "        \n",
    "        # Extraer el texto de esos elementos\n",
    "        text = '\\n'.join([element.get_text(separator='\\n').strip() for element in elements])\n",
    "        return text\n",
    "    else:\n",
    "        return f\"Error: Unable to fetch the page. Status code: {response.status_code}\"\n",
    "\n",
    "url = "JOB_DESCRIPTION_LINK_HERE",
    "class_name = 'wiki-content'\n",
    "job_description = extract_text_from_class(url, class_name)\n",
    "\n",
    "#print(page_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4f23468-20ea-407e-ac85-cc8e2cf6f226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "cv_path = './resources/data-engineer-resume-example.pdf'\n",
    "cv_text = extract_text_from_pdf(cv_path)\n",
    "\n",
    "#print(pdf_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3430549e-7dd9-4de9-8d28-ea5163613c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "roles = [\"data engineer\",\"full stack developer\",\"machine learning engineer\",\"data scientist\"]\n",
    "seniority_dict = {\n",
    "    \"senior\" : \"more than 4 years of expertise\",\n",
    "    \"mid-senior\" : \"between 2 and 4 years of experience\",\n",
    "    \"junior\" : \"between 0 and 2 years of experience\"\n",
    "}\n",
    "\n",
    "prompt = (\n",
    "    f\"hi, I want you to classify the following curriculum content: {cv_text} into the role which matches the best among this roles: {roles}, and experise based on: {seniority_dict}\"\n",
    "    f\"I want you also to give me a percentage match based on this job description: {job_description} and the reasons of it in a summarized way\"\n",
    ")\n",
    "#print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "596edc2d-1804-47df-bfc9-440bf16cddf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided curriculum content, I would classify the following roles into three categories:\n",
       "\n",
       "1. **Data Engineer**: Based on the job description, the role matches with \"Data Engineer\" as the best match among the options.\n",
       "\n",
       "2. **Full Stack Developer**: Although the individual has expertise in Python and other programming languages, there is no direct mention of web development skills or experience in full stack development.\n",
       "\n",
       "3. **Machine Learning Engineer**: There is no explicit mention of machine learning expertise, but the individual does have experience with Apache Spark and ETL processes, which could be related to data engineering or data science.\n",
       "\n",
       "As for the experience level, I would categorize the individual as a **mid-senior** Data Engineer based on their experience:\n",
       "\n",
       "- Led large-scale migration projects (e.g., Oracle to Redshift)\n",
       "- Designed and implemented real-time data pipelines\n",
       "- Managed and maintained cloud data storage systems\n",
       "- Collaborated with data scientists and analysts\n",
       "\n",
       "However, I would note that the individual's most recent role as a Data Engineer Intern at the Federal Reserve Board of Governors suggests they may still be in the **junior** or **mid-senior** range, depending on the specific details of their experience.\n",
       "\n",
       "To calculate the percentage match based on the job description:\n",
       "\n",
       "* **Data Engineer**: 95% (high level expertise, relevant skills and responsibilities)\n",
       "* **Full Stack Developer**: 5% (some overlap with Python programming skills, but no direct relevance to web development)\n",
       "* **Machine Learning Engineer**: 0% (no explicit mention of machine learning expertise)\n",
       "\n",
       "For the experience level:\n",
       "\n",
       "* **Junior/Mid Senior/Senior**: I would categorize the individual as a mid-senior Data Engineer, which corresponds to approximately 80% match."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ollama\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "response = ollama.chat(\n",
    "    model=\"llama3.2\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "markdown_content = response[\"message\"][\"content\"]\n",
    "\n",
    "display(Markdown(markdown_content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
